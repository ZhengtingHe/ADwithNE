{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import sys\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from model import ParticleEventTransformer\n",
    "from data import get_database_path, get_h5_files, read_h5_file, select_events\n",
    "from utils import load_toml_config\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if sys.platform == \"darwin\" else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['SM', 'neutral_boson', 'leptoquark', 'neutral_Higgs', 'charged_Higgs'])\n"
     ]
    }
   ],
   "source": [
    "files = load_toml_config(\"file\")\n",
    "database_path = get_database_path()\n",
    "bkg_files, sig_files = get_h5_files()\n",
    "\n",
    "print(files.keys())\n",
    "bkg = read_h5_file(database_path, files[\"SM\"])\n",
    "# SM processes\n",
    "\n",
    "neutral_boson = read_h5_file(database_path, files[\"neutral_boson\"])\n",
    "# A neutral scalar boson (A) with mass 50 GeV, decaying to two off-shell Z bosons, each forced to decay to two leptons: A → 4l\n",
    "\n",
    "leptoquark = read_h5_file(database_path, files[\"leptoquark\"])\n",
    "# A leptoquark (LQ) with mass 80 GeV, decaying to a b quark and a τ lepton24\n",
    "\n",
    "neutral_Higgs = read_h5_file(database_path, files[\"neutral_Higgs\"])\n",
    "# A scalar boson with mass 60 GeV, decaying to two tau leptons: h0→ ττ\n",
    "\n",
    "charged_Higgs = read_h5_file(database_path, files[\"charged_Higgs\"])\n",
    "# A charged scalar boson with mass 60 GeV, decaying to a tau lepton and a neutrino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_size': 3, 'embed_size': 16, 'num_heads': 8, 'num_layers': 4, 'hidden_dim': 256, 'output_dim': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/desmondhe/anaconda3/envs/ad/lib/python3.11/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ParticleEventTransformer(\n",
       "  (particle_embedding): Linear(in_features=3, out_features=16, bias=True)\n",
       "  (pos_encoder): ParticlePositionalEncoding()\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=16, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=16, bias=True)\n",
       "        (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Linear(in_features=304, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hyper_parameters = load_toml_config(\"Transformer\")\n",
    "print(model_hyper_parameters)\n",
    "feature_size = model_hyper_parameters[\"feature_size\"]\n",
    "embed_size = model_hyper_parameters[\"embed_size\"]\n",
    "num_heads = model_hyper_parameters[\"num_heads\"]\n",
    "num_layers = model_hyper_parameters[\"num_layers\"]\n",
    "hidden_dim = model_hyper_parameters[\"hidden_dim\"]\n",
    "output_dim = model_hyper_parameters[\"output_dim\"]\n",
    "\n",
    "model = ParticleEventTransformer(feature_size, embed_size, num_heads, hidden_dim, output_dim, num_layers)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis import inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import EventDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_test_num = 100000\n",
    "bkg_infer_test = bkg[:infer_test_num]\n",
    "infer_dataset = EventDataset(bkg_infer_test)\n",
    "infer_dataloader = DataLoader(infer_dataset, batch_size=256, num_workers=16, prefetch_factor=5)\n",
    "\n",
    "neutral_boson_infer_test = neutral_boson[:infer_test_num]\n",
    "neutral_boson_infer_dataset = EventDataset(neutral_boson_infer_test)\n",
    "neutral_boson_infer_dataloader = DataLoader(infer_dataset, batch_size=256, num_workers=16, prefetch_factor=5)\n",
    "\n",
    "leptoquark_infer_test = leptoquark[:infer_test_num]\n",
    "neutral_boson_infer_dataset = EventDataset(leptoquark_infer_test)\n",
    "neutral_boson_infer_dataloader = DataLoader(infer_dataset, batch_size=256, num_workers=16, prefetch_factor=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/391 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:01<00:00, 268.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"checkpoint.pt\"))\n",
    "\n",
    "bkg_embed_points = inference(model, infer_dataloader, embed_dim=output_dim)\n",
    "print(bkg_embed_points.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391/391 [00:01<00:00, 303.63it/s]\n"
     ]
    }
   ],
   "source": [
    "neutral_boson_embed_points = inference(model, neutral_boson_infer_dataloader, embed_dim=output_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifyDataset(Dataset):\n",
    "    def __init__(self, bkg_event, sig_event):\n",
    "        bkg_events = torch.from_numpy(bkg_event).float()\n",
    "        sig_events = torch.from_numpy(sig_event).float()\n",
    "        self.events = torch.cat([bkg_events, sig_events], dim=0)\n",
    "        self.labels = torch.cat([torch.zeros(len(bkg_events)), torch.ones(len(sig_events))])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.events)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.events[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ratio = 0.2\n",
    "train_num = int(len(bkg_embed_points) * (1 - val_ratio))\n",
    "\n",
    "train_dataset = ClassifyDataset(bkg_embed_points[:train_num], neutral_boson_embed_points[:train_num])\n",
    "val_dataset = ClassifyDataset(bkg_embed_points[train_num:], neutral_boson_embed_points[train_num:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=256, num_workers=16, prefetch_factor=5, shuffle=True, pin_memory=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=256, num_workers=16, prefetch_factor=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import MLP\n",
    "hidden_dim = [8, 16, 16, 8]\n",
    "naive_model = MLP(output_dim, hidden_sizes=hidden_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryACCUpdater(nn.Module):\n",
    "    def __init__(self, threshold=0.5):\n",
    "        super(BinaryACCUpdater, self).__init__()\n",
    "        self.total_acc = 0\n",
    "        self.count = 0\n",
    "        self.threshold = threshold\n",
    "    def forward(self, output, label):\n",
    "        acc = (output > self.threshold).float() == label\n",
    "        self.update(acc)\n",
    "        return acc\n",
    "    def update(self, metric):\n",
    "        self.total_acc += metric\n",
    "        self.count += 1\n",
    "    def compute(self):\n",
    "        return self.total_acc / self.count\n",
    "    def reset(self):\n",
    "        self.total_acc = 0\n",
    "        self.count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "loss_fn = nn.BCELoss()\n",
    "from torcheval.metrics import BinaryAccuracy\n",
    "acc_metric = BinaryACCUpdater()\n",
    "metric_dict = {\"Accuracy\": acc_metric}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classify import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
