{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from model import ParticleEventTransformer\n",
    "from data import get_database_path, get_h5_files, read_h5_file, select_events\n",
    "from utils import load_toml_config\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if sys.platform == \"darwin\" else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMD_config = load_toml_config(\"EMD\")\n",
    "particle_type_scale = EMD_config['particle_type_scale']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load raw events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['SM', 'neutral_boson', 'leptoquark', 'neutral_Higgs', 'charged_Higgs'])\n"
     ]
    }
   ],
   "source": [
    "files = load_toml_config(\"file\")\n",
    "database_path = get_database_path()\n",
    "bkg_files, sig_files = get_h5_files()\n",
    "\n",
    "print(files.keys())\n",
    "bkg = read_h5_file(database_path, files[\"SM\"])\n",
    "# SM processes\n",
    "\n",
    "neutral_boson = read_h5_file(database_path, files[\"neutral_boson\"])\n",
    "# A neutral scalar boson (A) with mass 50 GeV, decaying to two off-shell Z bosons, each forced to decay to two leptons: A → 4l\n",
    "\n",
    "leptoquark = read_h5_file(database_path, files[\"leptoquark\"])\n",
    "# A leptoquark (LQ) with mass 80 GeV, decaying to a b quark and a τ lepton24\n",
    "\n",
    "neutral_Higgs = read_h5_file(database_path, files[\"neutral_Higgs\"])\n",
    "# A scalar boson with mass 60 GeV, decaying to two tau leptons: h0→ ττ\n",
    "\n",
    "charged_Higgs = read_h5_file(database_path, files[\"charged_Higgs\"])\n",
    "# A charged scalar boson with mass 60 GeV, decaying to a tau lepton and a neutrino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_size': 3, 'embed_size': 16, 'num_heads': 8, 'num_layers': 4, 'hidden_dim': 256, 'output_dim': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/desmondhe/anaconda3/envs/ad/lib/python3.11/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "model_hyper_parameters = load_toml_config(\"Transformer\")\n",
    "print(model_hyper_parameters)\n",
    "feature_size = model_hyper_parameters[\"feature_size\"]\n",
    "embed_size = model_hyper_parameters[\"embed_size\"]\n",
    "num_heads = model_hyper_parameters[\"num_heads\"]\n",
    "num_layers = model_hyper_parameters[\"num_layers\"]\n",
    "hidden_dim = model_hyper_parameters[\"hidden_dim\"]\n",
    "output_dim = model_hyper_parameters[\"output_dim\"]\n",
    "\n",
    "embedding_model = ParticleEventTransformer(feature_size, embed_size, num_heads, hidden_dim, output_dim, num_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis import inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import EventDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_test_num = 1000000\n",
    "bkg_infer_test = bkg[:infer_test_num]\n",
    "infer_dataset = EventDataset(bkg_infer_test)\n",
    "infer_dataloader = DataLoader(infer_dataset, batch_size=256, num_workers=16, prefetch_factor=5)\n",
    "\n",
    "neutral_boson_infer_test = neutral_boson[:infer_test_num]\n",
    "neutral_boson_infer_dataset = EventDataset(neutral_boson_infer_test)\n",
    "neutral_boson_infer_dataloader = DataLoader(neutral_boson_infer_dataset, batch_size=256, num_workers=16, prefetch_factor=5)\n",
    "\n",
    "leptoquark_infer_test = leptoquark[:infer_test_num]\n",
    "leptoquark_infer_dataset = EventDataset(leptoquark_infer_test)\n",
    "leptoquark_infer_dataloader = DataLoader(leptoquark_infer_dataset, batch_size=256, num_workers=16, prefetch_factor=5)\n",
    "\n",
    "neutral_Higgs_infer_test = neutral_Higgs[:infer_test_num]\n",
    "neutral_Higgs_infer_dataset = EventDataset(neutral_Higgs_infer_test)\n",
    "neutral_Higgs_infer_dataloader = DataLoader(neutral_Higgs_infer_dataset, batch_size=256, num_workers=16, prefetch_factor=5)\n",
    "\n",
    "charged_Higgs_infer_test = charged_Higgs[:infer_test_num]\n",
    "charged_Higgs_infer_dataset = EventDataset(charged_Higgs_infer_test)\n",
    "charged_Higgs_infer_dataloader = DataLoader(charged_Higgs_infer_dataset, batch_size=256, num_workers=16, prefetch_factor=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3907/3907 [00:08<00:00, 444.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "embedding_model.load_state_dict(torch.load(os.path.join(\"..\", \"model\",\"emb_dim{}_type_scale{}.pt\".format(output_dim, particle_type_scale))))\n",
    "embedding_model.to(device)\n",
    "bkg_embed_points = inference(embedding_model, infer_dataloader, embed_dim=output_dim)\n",
    "print(bkg_embed_points.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 219/219 [00:01<00:00, 166.25it/s]\n",
      "100%|██████████| 1331/1331 [00:03<00:00, 379.29it/s]\n",
      "100%|██████████| 2701/2701 [00:06<00:00, 430.40it/s]\n",
      "100%|██████████| 2970/2970 [00:06<00:00, 433.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55969, 4)\n",
      "(340544, 4)\n",
      "(691283, 4)\n",
      "(760272, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "neutral_boson_embed_points = inference(embedding_model, neutral_boson_infer_dataloader, embed_dim=output_dim)\n",
    "leptoquark_embed_points = inference(embedding_model, leptoquark_infer_dataloader, embed_dim=output_dim)\n",
    "neutral_Higgs_embed_points = inference(embedding_model, neutral_Higgs_infer_dataloader, embed_dim=output_dim)\n",
    "charged_Higgs_embed_points = inference(embedding_model, charged_Higgs_infer_dataloader, embed_dim=output_dim)\n",
    "print(neutral_boson_embed_points.shape)\n",
    "print(leptoquark_embed_points.shape)\n",
    "print(neutral_Higgs_embed_points.shape)\n",
    "print(charged_Higgs_embed_points.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg_max = np.max(bkg_embed_points, axis=0)\n",
    "bkg_min = np.min(bkg_embed_points, axis=0)\n",
    "neutral_boson_max = np.max(neutral_boson_embed_points, axis=0)\n",
    "neutral_boson_min = np.min(neutral_boson_embed_points, axis=0)\n",
    "leptoquark_max = np.max(leptoquark_embed_points, axis=0)\n",
    "leptoquark_min = np.min(leptoquark_embed_points, axis=0)\n",
    "neutral_Higgs_max = np.max(neutral_Higgs_embed_points, axis=0)\n",
    "neutral_Higgs_min = np.min(neutral_Higgs_embed_points, axis=0)\n",
    "charged_Higgs_max = np.max(charged_Higgs_embed_points, axis=0)\n",
    "charged_Higgs_min = np.min(charged_Higgs_embed_points, axis=0)\n",
    "\n",
    "total_max = np.max(np.array([bkg_max, neutral_boson_max, leptoquark_max, neutral_Higgs_max, charged_Higgs_max]), axis=0)\n",
    "total_min = np.min(np.array([bkg_min, neutral_boson_min, leptoquark_min, neutral_Higgs_min, charged_Higgs_min]), axis=0)\n",
    "def max_min_norm(x):\n",
    "    return (x - total_min) / (total_max - total_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  96.99357097 -146.39087979 -153.85605629  108.39926677]\n"
     ]
    }
   ],
   "source": [
    "total_mean = np.mean(np.concatenate([bkg_embed_points, neutral_boson_embed_points, leptoquark_embed_points, neutral_Higgs_embed_points, charged_Higgs_embed_points]), axis=0)\n",
    "print(total_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 142.22429516 -210.5637264  -216.82394047  151.97081285]\n",
      "[ 107.49868192 -170.3974457  -157.23823675  100.49644183]\n",
      "[  92.40992917 -147.39542323 -141.82567862   92.84759197]\n",
      "[  97.29988844 -146.78354556 -152.84559856  107.3628698 ]\n",
      "[ 38.50199811 -59.40884638 -77.09169267  59.57889759]\n",
      "[39.62446888 46.32809639 53.42689661 45.55258798]\n",
      "[ 58.95394267  93.2374391  102.7732609   66.65062966]\n",
      "[49.01006039 88.06157974 92.52305241 51.4553242 ]\n",
      "[ 73.25371751 113.53638687 114.03525047  72.54167018]\n",
      "[ 80.00088338 128.19388221 131.19922904  82.24994631]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(bkg_embed_points, axis=0))\n",
    "print(np.mean(neutral_boson_embed_points, axis=0))\n",
    "print(np.mean(leptoquark_embed_points, axis=0))\n",
    "print(np.mean(neutral_Higgs_embed_points, axis=0))\n",
    "print(np.mean(charged_Higgs_embed_points, axis=0))\n",
    "\n",
    "print(np.std(bkg_embed_points, axis=0))\n",
    "print(np.std(neutral_boson_embed_points, axis=0))\n",
    "print(np.std(leptoquark_embed_points, axis=0))\n",
    "print(np.std(neutral_Higgs_embed_points, axis=0))\n",
    "print(np.std(charged_Higgs_embed_points, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split embed points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_exp_bkg_events(ori_bkg_events, ori_sig_events, sig_lambda, n=100000):\n",
    "    \"\"\"\n",
    "    Create expperiment events by combining pure signal and background events with signal strength lambda, \n",
    "    and return the background events from remaining pure background events.\n",
    "    Background: X = {X1,...,X_mb}, Xi ∼ pb Signal: Y = {Y1,...,Y_ms}, Experimental: W = {W1,...,W_n},\n",
    "    \"\"\"\n",
    "    m_s = int(n * sig_lambda)\n",
    "    m_b = n - m_s\n",
    "    exp_events = np.concatenate((ori_bkg_events[:m_b], ori_sig_events[:m_s]))\n",
    "    np.random.shuffle(exp_events)\n",
    "    bkg_events = ori_bkg_events[m_b:m_b + n]\n",
    "    return exp_events, bkg_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(exp_events, bkg_events, test_ratio=0.2):\n",
    "    \"\"\"\n",
    "    Split background data X = {X1,...,X_mb} into X1 and X2 of sizes m1 and m2 respectively.\n",
    "    Split experimental data W = {W1,...,W_n} into W1 and W2 of sizes n1 and n2 respectively, with n2 = m2.\n",
    "    Will assume n = mb for now.\n",
    "    \"\"\"\n",
    "    n1 = int((1 - test_ratio) * len(exp_events))\n",
    "    m1 = n1\n",
    "    X1 = bkg_events[:m1]\n",
    "    X2 = bkg_events[m1:]\n",
    "    W1 = exp_events[:n1]\n",
    "    W2 = exp_events[n1:]\n",
    "    return X1, X2, W1, W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifyDataset(Dataset):\n",
    "    def __init__(self, exp_events ,bkg_events):\n",
    "        \"\"\"\n",
    "        Experiment events labeled as 1, background events labeled as 0.\n",
    "        \"\"\"\n",
    "        # Normalize the data\n",
    "        bkg_events = max_min_norm(bkg_events)\n",
    "        exp_events = max_min_norm(exp_events)\n",
    "\n",
    "        bkg_events = torch.from_numpy(bkg_events).float()\n",
    "        exp_events = torch.from_numpy(exp_events).float()\n",
    "        self.events = torch.cat([bkg_events, exp_events], dim=0)\n",
    "        self.labels = torch.cat([torch.zeros(len(bkg_events)), torch.ones(len(exp_events))])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.events)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.events[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(X1, W1, val_ratio):\n",
    "    \"\"\"\n",
    "    Get dataloaders for training and validation sets.\n",
    "    \"\"\"\n",
    "    n_train = int((1 - val_ratio) * len(W1))\n",
    "    X1_train = X1[:n_train]\n",
    "    X1_val = X1[n_train:]\n",
    "    W1_train = W1[:n_train]\n",
    "    W1_val = W1[n_train:]\n",
    "    \n",
    "    train_dataset = ClassifyDataset(W1_train, X1_train)\n",
    "    val_dataset = ClassifyDataset(W1_val, X1_val)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=256)\n",
    "    return train_dataloader, val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio=0.2\n",
    "val_ratio = 0.2\n",
    "sig_lambda = 0.5\n",
    "n = 100000\n",
    "\n",
    "exp_events, bkg_events = create_exp_bkg_events(bkg_embed_points, charged_Higgs_embed_points, sig_lambda, n)\n",
    "X1, X2, W1, W2 = train_test_split(exp_events, bkg_events, test_ratio)\n",
    "n1 = len(W1)\n",
    "m1 = len(X1)\n",
    "n2 = len(W2)\n",
    "m2 = len(X2)\n",
    "train_dataloader, val_dataloader = get_dataloaders(X1, W1, val_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes):\n",
    "        super(MLP, self).__init__()\n",
    "        def make_layer(in_size, out_size):\n",
    "            layer = nn.Sequential(\n",
    "                nn.Linear(in_size, out_size),\n",
    "                nn.LeakyReLU(),\n",
    "                # nn.Dropout(0.1)\n",
    "            )\n",
    "            nn.init.kaiming_normal_(layer[0].weight, nonlinearity='leaky_relu')\n",
    "            return layer\n",
    "        self.layers = nn.Sequential(\n",
    "            make_layer(input_size, hidden_sizes[0]),\n",
    "            *[make_layer(hidden_sizes[i], hidden_sizes[i+1]) for i in range(len(hidden_sizes)-1)],\n",
    "            nn.Linear(hidden_sizes[-1], 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x).reshape(-1)\n",
    "hidden_dim = [8, 16, 16, 16, 8]\n",
    "naive_model = MLP(output_dim, hidden_sizes=hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Deep(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.layer1 = nn.Linear(4, 8)\n",
    "#         self.act1 = nn.ReLU()\n",
    "#         self.layer2 = nn.Linear(8, 16)\n",
    "#         self.act2 = nn.ReLU()\n",
    "#         self.layer3 = nn.Linear(16, 16)\n",
    "#         self.act3 = nn.ReLU()\n",
    "#         self.output = nn.Linear(16, 1)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    " \n",
    "#     def forward(self, x):\n",
    "#         x = self.act1(self.layer1(x))\n",
    "#         x = self.act2(self.layer2(x))\n",
    "#         x = self.act3(self.layer3(x))\n",
    "#         x = self.sigmoid(self.output(x))\n",
    "#         x = x.squeeze()\n",
    "#         return x\n",
    "\n",
    "# naive_model = Deep()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryACCUpdater(nn.Module):\n",
    "    def __init__(self, threshold=0.5):\n",
    "        super(BinaryACCUpdater, self).__init__()\n",
    "        self.total_acc = 0\n",
    "        self.count = 0\n",
    "        self.threshold = threshold\n",
    "    def forward(self, output, label):\n",
    "        acc = (output > self.threshold).float() == label\n",
    "        mean_acc = acc.float().mean()\n",
    "        self.update(mean_acc)\n",
    "        return mean_acc\n",
    "    def update(self, metric):\n",
    "        self.total_acc += metric\n",
    "        self.count += 1\n",
    "    def compute(self):\n",
    "        return self.total_acc / self.count\n",
    "    def reset(self):\n",
    "        self.total_acc = 0\n",
    "        self.count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_model.to(device)\n",
    "optimizer = torch.optim.Adam(naive_model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "loss_fn = nn.BCELoss()\n",
    "acc_metric = BinaryACCUpdater()\n",
    "metric_dict = {\"Accuracy\": acc_metric}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classify import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_train_model  = torch.compile(train_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2024-05-13 00:24:30\n",
      "Epoch 1 / 50\n",
      "\n",
      "  0%|          | 0/4000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/desmondhe/anaconda3/envs/ad/lib/python3.11/site-packages/torch/_inductor/compile_fx.py:140: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [00:13<00:00, 291.16it/s, train_Accuracy=0.679, train_loss=0.59] \n",
      "100%|██████████| 125/125 [00:02<00:00, 45.75it/s, val_Accuracy=0.682, val_loss=0.583]\n",
      "<<<<<< reach best val_Accuracy : 0.682187557220459 >>>>>>\n",
      "\n",
      "================================================================================2024-05-13 00:24:47\n",
      "Epoch 2 / 50\n",
      "\n",
      "100%|██████████| 4000/4000 [00:07<00:00, 538.54it/s, train_Accuracy=0.683, train_loss=0.584]\n",
      "100%|██████████| 125/125 [00:00<00:00, 647.64it/s, val_Accuracy=0.682, val_loss=0.583]\n",
      "\n",
      "================================================================================2024-05-13 00:24:54\n",
      "Epoch 3 / 50\n",
      "\n",
      "100%|██████████| 4000/4000 [00:07<00:00, 551.34it/s, train_Accuracy=0.683, train_loss=0.583]\n",
      "100%|██████████| 125/125 [00:00<00:00, 578.21it/s, val_Accuracy=0.684, val_loss=0.581]\n",
      "<<<<<< reach best val_Accuracy : 0.6840937733650208 >>>>>>\n",
      "\n",
      "================================================================================2024-05-13 00:25:02\n",
      "Epoch 4 / 50\n",
      "\n",
      "100%|██████████| 4000/4000 [00:07<00:00, 550.34it/s, train_Accuracy=0.684, train_loss=0.583]\n",
      "100%|██████████| 125/125 [00:00<00:00, 349.95it/s, val_Accuracy=0.685, val_loss=0.581]\n",
      "<<<<<< reach best val_Accuracy : 0.6851875185966492 >>>>>>\n",
      "\n",
      "================================================================================2024-05-13 00:25:10\n",
      "Epoch 5 / 50\n",
      "\n",
      "100%|██████████| 4000/4000 [00:07<00:00, 553.89it/s, train_Accuracy=0.684, train_loss=0.583]\n",
      "100%|██████████| 125/125 [00:00<00:00, 641.49it/s, val_Accuracy=0.684, val_loss=0.582]\n",
      "\n",
      "================================================================================2024-05-13 00:25:17\n",
      "Epoch 6 / 50\n",
      "\n",
      "100%|██████████| 4000/4000 [00:07<00:00, 557.35it/s, train_Accuracy=0.684, train_loss=0.582]\n",
      "100%|██████████| 125/125 [00:00<00:00, 561.55it/s, val_Accuracy=0.682, val_loss=0.586]\n",
      "\n",
      "================================================================================2024-05-13 00:25:24\n",
      "Epoch 7 / 50\n",
      "\n",
      "100%|██████████| 4000/4000 [00:07<00:00, 549.64it/s, train_Accuracy=0.684, train_loss=0.582]\n",
      "100%|██████████| 125/125 [00:00<00:00, 630.05it/s, val_Accuracy=0.684, val_loss=0.582]\n",
      "\n",
      "================================================================================2024-05-13 00:25:32\n",
      "Epoch 8 / 50\n",
      "\n",
      "100%|██████████| 4000/4000 [00:07<00:00, 561.88it/s, train_Accuracy=0.684, train_loss=0.582]\n",
      "100%|██████████| 125/125 [00:00<00:00, 621.54it/s, val_Accuracy=0.686, val_loss=0.581]\n",
      "<<<<<< reach best val_Accuracy : 0.6855937838554382 >>>>>>\n",
      "\n",
      "================================================================================2024-05-13 00:25:39\n",
      "Epoch 9 / 50\n",
      "\n",
      "100%|██████████| 4000/4000 [00:07<00:00, 570.44it/s, train_Accuracy=0.684, train_loss=0.582]\n",
      "100%|██████████| 125/125 [00:00<00:00, 558.52it/s, val_Accuracy=0.686, val_loss=0.581]\n",
      "<<<<<< reach best val_Accuracy : 0.6857500076293945 >>>>>>\n",
      "\n",
      "================================================================================2024-05-13 00:25:46\n",
      "Epoch 10 / 50\n",
      "\n",
      "100%|██████████| 4000/4000 [00:07<00:00, 532.77it/s, train_Accuracy=0.685, train_loss=0.582]\n",
      "100%|██████████| 125/125 [00:00<00:00, 696.06it/s, val_Accuracy=0.685, val_loss=0.581]\n",
      "\n",
      "================================================================================2024-05-13 00:25:54\n",
      "Epoch 11 / 50\n",
      "\n",
      "100%|██████████| 4000/4000 [00:07<00:00, 556.33it/s, train_Accuracy=0.684, train_loss=0.582]\n",
      "100%|██████████| 125/125 [00:00<00:00, 344.75it/s, val_Accuracy=0.684, val_loss=0.581]\n",
      "\n",
      "================================================================================2024-05-13 00:26:02\n",
      "Epoch 12 / 50\n",
      "\n",
      "100%|██████████| 4000/4000 [00:07<00:00, 545.28it/s, train_Accuracy=0.685, train_loss=0.582]\n",
      "100%|██████████| 125/125 [00:00<00:00, 579.03it/s, val_Accuracy=0.685, val_loss=0.583]\n",
      "\n",
      "================================================================================2024-05-13 00:26:09\n",
      "Epoch 13 / 50\n",
      "\n",
      "100%|██████████| 4000/4000 [00:06<00:00, 574.49it/s, train_Accuracy=0.684, train_loss=0.582]\n",
      "100%|██████████| 125/125 [00:00<00:00, 608.64it/s, val_Accuracy=0.685, val_loss=0.58] \n",
      "\n",
      "================================================================================2024-05-13 00:26:16\n",
      "Epoch 14 / 50\n",
      "\n",
      "100%|██████████| 4000/4000 [00:07<00:00, 558.43it/s, train_Accuracy=0.684, train_loss=0.582]\n",
      "100%|██████████| 125/125 [00:00<00:00, 638.94it/s, val_Accuracy=0.684, val_loss=0.58]\n",
      "<<<<<< val_Accuracy without improvement in 5 epoch, early stopping >>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_Accuracy</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.590087</td>\n",
       "      <td>0.678859</td>\n",
       "      <td>0.582665</td>\n",
       "      <td>0.682188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.583989</td>\n",
       "      <td>0.682930</td>\n",
       "      <td>0.583346</td>\n",
       "      <td>0.682125</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.583309</td>\n",
       "      <td>0.682953</td>\n",
       "      <td>0.580906</td>\n",
       "      <td>0.684094</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.582899</td>\n",
       "      <td>0.683648</td>\n",
       "      <td>0.581058</td>\n",
       "      <td>0.685188</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.582612</td>\n",
       "      <td>0.683844</td>\n",
       "      <td>0.581982</td>\n",
       "      <td>0.684406</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.582463</td>\n",
       "      <td>0.683773</td>\n",
       "      <td>0.585691</td>\n",
       "      <td>0.681594</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.582380</td>\n",
       "      <td>0.684273</td>\n",
       "      <td>0.581568</td>\n",
       "      <td>0.683688</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.582009</td>\n",
       "      <td>0.684008</td>\n",
       "      <td>0.580900</td>\n",
       "      <td>0.685594</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.581950</td>\n",
       "      <td>0.684031</td>\n",
       "      <td>0.580823</td>\n",
       "      <td>0.685750</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.582002</td>\n",
       "      <td>0.684852</td>\n",
       "      <td>0.580842</td>\n",
       "      <td>0.684781</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.582112</td>\n",
       "      <td>0.684484</td>\n",
       "      <td>0.580939</td>\n",
       "      <td>0.684313</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.581954</td>\n",
       "      <td>0.684500</td>\n",
       "      <td>0.583235</td>\n",
       "      <td>0.684969</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.581873</td>\n",
       "      <td>0.684031</td>\n",
       "      <td>0.580219</td>\n",
       "      <td>0.684656</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.582009</td>\n",
       "      <td>0.684266</td>\n",
       "      <td>0.580311</td>\n",
       "      <td>0.684281</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_loss  train_Accuracy  val_loss  val_Accuracy  epoch\n",
       "0     0.590087        0.678859  0.582665      0.682188      1\n",
       "1     0.583989        0.682930  0.583346      0.682125      2\n",
       "2     0.583309        0.682953  0.580906      0.684094      3\n",
       "3     0.582899        0.683648  0.581058      0.685188      4\n",
       "4     0.582612        0.683844  0.581982      0.684406      5\n",
       "5     0.582463        0.683773  0.585691      0.681594      6\n",
       "6     0.582380        0.684273  0.581568      0.683688      7\n",
       "7     0.582009        0.684008  0.580900      0.685594      8\n",
       "8     0.581950        0.684031  0.580823      0.685750      9\n",
       "9     0.582002        0.684852  0.580842      0.684781     10\n",
       "10    0.582112        0.684484  0.580939      0.684313     11\n",
       "11    0.581954        0.684500  0.583235      0.684969     12\n",
       "12    0.581873        0.684031  0.580219      0.684656     13\n",
       "13    0.582009        0.684266  0.580311      0.684281     14"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_train_model(\n",
    "    naive_model, optimizer,\n",
    "    loss_fn, metrics_dict=metric_dict,\n",
    "    train_dataloader=train_dataloader, val_dataloader=val_dataloader,\n",
    "    monitor=\"val_Accuracy\", mode=\"max\",\n",
    "    epochs=50\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict(model, dataloader):\n",
    "    model.eval()\n",
    "    batch_size = dataloader.batch_size\n",
    "    targets = np.zeros(len(dataloader.dataset))\n",
    "    predictions = np.zeros(len(dataloader.dataset))\n",
    "    for i, (features, labels) in enumerate(tqdm(dataloader)):\n",
    "        features = features.to(device)\n",
    "        outputs = model(features)\n",
    "        targets[i * batch_size: (i + 1) * batch_size] = labels.numpy()\n",
    "        predictions[i * batch_size: (i + 1) * batch_size] = outputs.cpu().numpy()\n",
    "    return targets, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:00<00:00, 1134.20it/s]\n"
     ]
    }
   ],
   "source": [
    "targets, predictions = predict(naive_model, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_auc(targets, predictions):\n",
    "    fpr, tpr, thersholds = roc_curve(targets, predictions)\n",
    "    auc_roc = auc(fpr, tpr)\n",
    "    return fpr, tpr, auc_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, auc_roc, title):\n",
    "    plt.plot(fpr, tpr, 'k--', label='ROC (area = {0:.2f})'.format(auc_roc), lw=2)    \n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('FPT')\n",
    "    plt.ylabel('TPR') \n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, auc_roc = calculate_auc(targets, predictions)\n",
    "plot_roc_curve(fpr, tpr, auc_roc, \"ROC Curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, events):\n",
    "        events = max_min_norm(events)\n",
    "        self.events = torch.from_numpy(events).float()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.events)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.events[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def h_hat(classifier, W):\n",
    "    classifier.eval()\n",
    "    W_dataset = TestDataset(W)\n",
    "    batch_size = 512\n",
    "    W_dataloader = DataLoader(W_dataset, batch_size=batch_size)\n",
    "    predictions = np.zeros(len(W))\n",
    "    for i, features in enumerate(tqdm(W_dataloader)):\n",
    "        features = features.to(device)\n",
    "        outputs = classifier(features)\n",
    "        predictions[i * batch_size: (i + 1) * batch_size] = outputs.cpu().numpy()\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrt(classifier, W):\n",
    "    pi = n1 / (m1 + n1)\n",
    "    h_W = h_hat(classifier, W)\n",
    "    return np.log((1 - pi) / pi) + (1 / n2) * np.sum(np.log(h_W / (1 - h_W)))\n",
    "\n",
    "\n",
    "def auc(classifier, W, X):\n",
    "    h_W = h_hat(classifier, W)\n",
    "    h_X = h_hat(classifier, X)\n",
    "    sum = 0\n",
    "    for w_j in h_W:\n",
    "        for x_i in h_X:\n",
    "            sum += w_j > x_i\n",
    "    return sum / (m2 * n2)\n",
    "    \n",
    "\n",
    "def mce(classifier, W, X):\n",
    "    pi = n1 / (m1 + n1)\n",
    "    h_W = h_hat(classifier, W)\n",
    "    h_X = h_hat(classifier, X)\n",
    "    x_sum = 0\n",
    "    w_sum = 0\n",
    "    for x_i in h_X:\n",
    "        x_sum += x_i > pi\n",
    "    for w_j in h_W:\n",
    "        w_sum += w_j < pi\n",
    "    return 0.5 * ((1/m2) * x_sum + (1/n2) * w_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 3 µs, total: 3 µs\n",
      "Wall time: 10 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 1085.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7366602673385082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "print(lrt(naive_model, W2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
      "Wall time: 5.96 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 963.65it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 1279.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7207634175\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "print(auc(naive_model, W2, X2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bootstrap_Permutation:\n",
    "    def __init__(self, X2, W2, classifier):\n",
    "        assert len(X2) == len(W2) # Make sure n2= m2\n",
    "        self.m2 = len(X2)\n",
    "        self.n2 = len(W2)\n",
    "\n",
    "        self.X2 = X2\n",
    "        self.W2 = W2\n",
    "        self.union_W2X2 = np.concatenate((self.X2, self.W2))\n",
    "\n",
    "        self.classifier = classifier\n",
    "\n",
    "        self.lrt_exp = lrt(self.classifier, self.W2)\n",
    "        self.auc_exp = auc(self.classifier, self.W2, self.X2)\n",
    "        self.mce_exp = mce(self.classifier, self.W2, self.X2)\n",
    "\n",
    "    def bootstrap(self, n):\n",
    "        lrt_null = np.zeros(n)\n",
    "        auc_null = np.zeros(n)\n",
    "        mce_null = np.zeros(n)\n",
    "        for i in tqdm(range(n)):\n",
    "            lrt_null = lrt(self.classifier, np.random.choice(self.union_W2X2, self.n2))\n",
    "            auc_null = auc(self.classifier, np.random.choice(self.union_W2X2, self.n2), np.random.choice(self.union_W2X2, self.m2))\n",
    "            mce_null = mce(self.classifier, np.random.choice(self.union_W2X2, self.n2), np.random.choice(self.union_W2X2, self.m2))\n",
    "        return lrt_null, auc_null, mce_null\n",
    "    def permutation(self, n):\n",
    "        lrt_null = np.zeros(n)\n",
    "        auc_null = np.zeros(n)\n",
    "        mce_null = np.zeros(n)\n",
    "        sample1 = self.union_W2X2.copy()\n",
    "        sample2 = self.union_W2X2.copy()\n",
    "        np.random.shuffle(sample1)\n",
    "        np.random.shuffle(sample2)\n",
    "        for i in tqdm(range(n)):\n",
    "            lrt_null = lrt(self.classifier, self.union_W2X2[np.random.choice(len(self.union_W2X2), self.n2, replace=False)])\n",
    "            auc_null = auc(self.classifier, sample1[:self.n2], sample1[self.n2:])\n",
    "            mce_null = mce(self.classifier, sample2[:self.n2], sample2[self.n2:])\n",
    "        return lrt_null, auc_null, mce_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 1236.74it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 1372.52it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 1375.63it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 815.83it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 1273.94it/s]\n"
     ]
    }
   ],
   "source": [
    "bootstrap_permutation = Bootstrap_Permutation(X2, W2, naive_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [02:01<1:05:14, 40.35s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m null_dist_bootstrap \u001b[38;5;241m=\u001b[39m bootstrap_permutation\u001b[38;5;241m.\u001b[39mpermutation(\u001b[38;5;241m100\u001b[39m)\n",
      "Cell \u001b[0;32mIn[43], line 36\u001b[0m, in \u001b[0;36mBootstrap_Permutation.permutation\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(n)):\n\u001b[1;32m     35\u001b[0m     lrt_null \u001b[38;5;241m=\u001b[39m lrt(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munion_W2X2[np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munion_W2X2), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn2, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)])\n\u001b[0;32m---> 36\u001b[0m     auc_null \u001b[38;5;241m=\u001b[39m auc(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier, sample1[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn2], sample1[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn2:])\n\u001b[1;32m     37\u001b[0m     mce_null \u001b[38;5;241m=\u001b[39m mce(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier, sample2[:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn2], sample2[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn2:])\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lrt_null, auc_null, mce_null\n",
      "Cell \u001b[0;32mIn[41], line 13\u001b[0m, in \u001b[0;36mauc\u001b[0;34m(classifier, W, X)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m w_j \u001b[38;5;129;01min\u001b[39;00m h_W:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x_i \u001b[38;5;129;01min\u001b[39;00m h_X:\n\u001b[0;32m---> 13\u001b[0m         \u001b[38;5;28msum\u001b[39m \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m w_j \u001b[38;5;241m>\u001b[39m x_i\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m \u001b[38;5;241m/\u001b[39m (m2 \u001b[38;5;241m*\u001b[39m n2)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "null_dist_bootstrap = bootstrap_permutation.permutation(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
