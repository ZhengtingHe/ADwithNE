{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import importlib\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from model import BaselineTransformer\n",
    "from data import get_database_path, read_h5_file\n",
    "from utils import load_toml_config\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if sys.platform == \"darwin\" else \"cpu\"\n",
    "random_seed = 114514\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMD_config = load_toml_config(\"EMD\")\n",
    "particle_type_scale = EMD_config['particle_type_scale']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load raw events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SM (13451915, 19, 4)\n",
      "neutral_boson (55969, 19, 4)\n",
      "leptoquark (340544, 19, 4)\n",
      "neutral_Higgs (691283, 19, 4)\n",
      "charged_Higgs (760272, 19, 4)\n"
     ]
    }
   ],
   "source": [
    "files = load_toml_config(\"file\")\n",
    "database_path = get_database_path()\n",
    "\n",
    "events = {}\n",
    "for key, value in files.items():\n",
    "    events[key] = read_h5_file(database_path, value)\n",
    "    print(key, events[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral_boson', 'leptoquark', 'neutral_Higgs', 'charged_Higgs']\n"
     ]
    }
   ],
   "source": [
    "signals = [key for key in events.keys() if key != \"SM\"]\n",
    "print(signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_size': 3, 'embed_size': 16, 'num_heads': 8, 'num_layers': 4, 'hidden_dim': 256, 'output_dim': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/desmondhe/anaconda3/envs/ad/lib/python3.11/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaselineTransformer(\n",
       "  (particle_embedding): Linear(in_features=3, out_features=16, bias=True)\n",
       "  (pos_encoder): ParticlePositionalEncoding()\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=16, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=16, bias=True)\n",
       "        (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Linear(in_features=304, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hyper_parameters = load_toml_config(\"Transformer\")\n",
    "print(model_hyper_parameters)\n",
    "feature_size = model_hyper_parameters[\"feature_size\"]\n",
    "embed_size = model_hyper_parameters[\"embed_size\"]\n",
    "num_heads = model_hyper_parameters[\"num_heads\"]\n",
    "num_layers = model_hyper_parameters[\"num_layers\"]\n",
    "hidden_dim = model_hyper_parameters[\"hidden_dim\"]\n",
    "\n",
    "\n",
    "classify_model = BaselineTransformer(feature_size, embed_size, num_heads, hidden_dim, num_layers)\n",
    "classify_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis import create_exp_bkg_events, train_test_split, get_dataloaders\n",
    "from data import EventDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio=0.2\n",
    "val_ratio = 0.2\n",
    "sig_lambda = 0.5\n",
    "n = 100000\n",
    "\n",
    "# test_signal = \"neutral_boson\"\n",
    "# test_signal = \"leptoquark\"\n",
    "# test_signal = \"neutral_Higgs\"\n",
    "test_signal = \"charged_Higgs\"\n",
    "\n",
    "exp_events, bkg_events = create_exp_bkg_events(events['SM'], events[test_signal], sig_lambda, n)\n",
    "X1, X2, W1, W2 = train_test_split(exp_events, bkg_events, test_ratio)\n",
    "n1 = len(W1)\n",
    "m1 = len(X1)\n",
    "pi = n1 / (n1 + m1)\n",
    "n2 = len(W2)\n",
    "m2 = len(X2)\n",
    "train_dataloader, val_dataloader = get_dataloaders(X1[:,:,:3], W1[:, :, :3], val_ratio, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import BinaryACCUpdater\n",
    "classify_model.to(device)\n",
    "optimizer = torch.optim.Adam(classify_model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "loss_fn = nn.BCELoss()\n",
    "acc_metric = BinaryACCUpdater()\n",
    "metric_dict = {\"Accuracy\": acc_metric}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classify import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================2024-05-31 20:57:37\n",
      "Epoch 1 / 50\n",
      "\n",
      "100%|██████████| 2000/2000 [00:13<00:00, 144.62it/s, train_Accuracy=0.676, train_loss=0.59] \n",
      "100%|██████████| 125/125 [00:00<00:00, 353.94it/s, val_Accuracy=0.682, val_loss=0.58] \n",
      "<<<<<< reach best val_Accuracy : 0.6817812919616699 >>>>>>\n",
      "\n",
      "================================================================================2024-05-31 20:57:51\n",
      "Epoch 2 / 50\n",
      "\n",
      "100%|██████████| 2000/2000 [00:13<00:00, 144.20it/s, train_Accuracy=0.684, train_loss=0.579]\n",
      "100%|██████████| 125/125 [00:00<00:00, 354.81it/s, val_Accuracy=0.676, val_loss=0.588]\n",
      "\n",
      "================================================================================2024-05-31 20:58:06\n",
      "Epoch 3 / 50\n",
      "\n",
      "100%|██████████| 2000/2000 [00:13<00:00, 145.01it/s, train_Accuracy=0.684, train_loss=0.578]\n",
      "100%|██████████| 125/125 [00:00<00:00, 352.31it/s, val_Accuracy=0.687, val_loss=0.572]\n",
      "<<<<<< reach best val_Accuracy : 0.6866875290870667 >>>>>>\n",
      "\n",
      "================================================================================2024-05-31 20:58:20\n",
      "Epoch 4 / 50\n",
      "\n",
      "100%|██████████| 2000/2000 [00:14<00:00, 142.85it/s, train_Accuracy=0.687, train_loss=0.576]\n",
      "100%|██████████| 125/125 [00:00<00:00, 265.14it/s, val_Accuracy=0.685, val_loss=0.575]\n",
      "\n",
      "================================================================================2024-05-31 20:58:35\n",
      "Epoch 5 / 50\n",
      "\n",
      "100%|██████████| 2000/2000 [00:13<00:00, 148.03it/s, train_Accuracy=0.688, train_loss=0.575]\n",
      "100%|██████████| 125/125 [00:00<00:00, 332.62it/s, val_Accuracy=0.691, val_loss=0.57] \n",
      "<<<<<< reach best val_Accuracy : 0.691031277179718 >>>>>>\n",
      "\n",
      "================================================================================2024-05-31 20:58:49\n",
      "Epoch 6 / 50\n",
      "\n",
      "100%|██████████| 2000/2000 [00:13<00:00, 144.06it/s, train_Accuracy=0.689, train_loss=0.575]\n",
      "100%|██████████| 125/125 [00:00<00:00, 347.06it/s, val_Accuracy=0.689, val_loss=0.572]\n",
      "\n",
      "================================================================================2024-05-31 20:59:03\n",
      "Epoch 7 / 50\n",
      "\n",
      "100%|██████████| 2000/2000 [00:14<00:00, 140.13it/s, train_Accuracy=0.689, train_loss=0.574]\n",
      "100%|██████████| 125/125 [00:00<00:00, 331.35it/s, val_Accuracy=0.69, val_loss=0.57] \n",
      "\n",
      "================================================================================2024-05-31 20:59:18\n",
      "Epoch 8 / 50\n",
      "\n",
      "100%|██████████| 2000/2000 [00:13<00:00, 144.27it/s, train_Accuracy=0.688, train_loss=0.574]\n",
      "100%|██████████| 125/125 [00:00<00:00, 339.74it/s, val_Accuracy=0.689, val_loss=0.57] \n",
      "\n",
      "================================================================================2024-05-31 20:59:33\n",
      "Epoch 9 / 50\n",
      "\n",
      "100%|██████████| 2000/2000 [00:14<00:00, 139.90it/s, train_Accuracy=0.689, train_loss=0.573]\n",
      "100%|██████████| 125/125 [00:00<00:00, 334.19it/s, val_Accuracy=0.69, val_loss=0.57]  \n",
      "\n",
      "================================================================================2024-05-31 20:59:47\n",
      "Epoch 10 / 50\n",
      "\n",
      "100%|██████████| 2000/2000 [00:14<00:00, 141.39it/s, train_Accuracy=0.689, train_loss=0.573]\n",
      "100%|██████████| 125/125 [00:00<00:00, 332.71it/s, val_Accuracy=0.693, val_loss=0.573]\n",
      "<<<<<< reach best val_Accuracy : 0.6925000548362732 >>>>>>\n",
      "\n",
      "================================================================================2024-05-31 21:00:02\n",
      "Epoch 11 / 50\n",
      "\n",
      "100%|██████████| 2000/2000 [00:14<00:00, 139.20it/s, train_Accuracy=0.689, train_loss=0.573]\n",
      "100%|██████████| 125/125 [00:00<00:00, 345.88it/s, val_Accuracy=0.69, val_loss=0.573] \n",
      "\n",
      "================================================================================2024-05-31 21:00:17\n",
      "Epoch 12 / 50\n",
      "\n",
      "100%|██████████| 2000/2000 [00:14<00:00, 141.54it/s, train_Accuracy=0.689, train_loss=0.573]\n",
      "100%|██████████| 125/125 [00:00<00:00, 250.65it/s, val_Accuracy=0.692, val_loss=0.568]\n",
      "\n",
      "================================================================================2024-05-31 21:00:32\n",
      "Epoch 13 / 50\n",
      "\n",
      "100%|██████████| 2000/2000 [00:13<00:00, 142.86it/s, train_Accuracy=0.69, train_loss=0.573] \n",
      "100%|██████████| 125/125 [00:00<00:00, 359.13it/s, val_Accuracy=0.693, val_loss=0.568]\n",
      "<<<<<< reach best val_Accuracy : 0.6925625205039978 >>>>>>\n",
      "\n",
      "================================================================================2024-05-31 21:00:46\n",
      "Epoch 14 / 50\n",
      "\n",
      "100%|██████████| 2000/2000 [00:14<00:00, 142.49it/s, train_Accuracy=0.69, train_loss=0.572] \n",
      "100%|██████████| 125/125 [00:00<00:00, 334.39it/s, val_Accuracy=0.692, val_loss=0.57] \n",
      "\n",
      "================================================================================2024-05-31 21:01:01\n",
      "Epoch 15 / 50\n",
      "\n",
      "100%|██████████| 2000/2000 [00:14<00:00, 142.08it/s, train_Accuracy=0.69, train_loss=0.572] \n",
      "100%|██████████| 125/125 [00:00<00:00, 341.47it/s, val_Accuracy=0.692, val_loss=0.569]\n",
      "\n",
      "================================================================================2024-05-31 21:01:16\n",
      "Epoch 16 / 50\n",
      "\n",
      "100%|██████████| 2000/2000 [00:14<00:00, 142.01it/s, train_Accuracy=0.689, train_loss=0.572]\n",
      "100%|██████████| 125/125 [00:00<00:00, 344.19it/s, val_Accuracy=0.692, val_loss=0.569]\n",
      "\n",
      "================================================================================2024-05-31 21:01:30\n",
      "Epoch 17 / 50\n",
      "\n",
      "100%|██████████| 2000/2000 [00:14<00:00, 142.39it/s, train_Accuracy=0.69, train_loss=0.572] \n",
      "100%|██████████| 125/125 [00:00<00:00, 337.30it/s, val_Accuracy=0.687, val_loss=0.573]\n",
      "\n",
      "================================================================================2024-05-31 21:01:45\n",
      "Epoch 18 / 50\n",
      "\n",
      "100%|██████████| 2000/2000 [00:13<00:00, 143.41it/s, train_Accuracy=0.691, train_loss=0.572]\n",
      "100%|██████████| 125/125 [00:00<00:00, 346.34it/s, val_Accuracy=0.69, val_loss=0.573] \n",
      "<<<<<< val_Accuracy without improvement in 5 epoch, early stopping >>>>>>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_Accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_Accuracy</th>\n",
       "      <th>epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.589603</td>\n",
       "      <td>0.675500</td>\n",
       "      <td>0.579704</td>\n",
       "      <td>0.681781</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.579434</td>\n",
       "      <td>0.683906</td>\n",
       "      <td>0.588434</td>\n",
       "      <td>0.675813</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.578238</td>\n",
       "      <td>0.683984</td>\n",
       "      <td>0.572195</td>\n",
       "      <td>0.686688</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.576355</td>\n",
       "      <td>0.687398</td>\n",
       "      <td>0.574973</td>\n",
       "      <td>0.685250</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.575338</td>\n",
       "      <td>0.687922</td>\n",
       "      <td>0.570307</td>\n",
       "      <td>0.691031</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.574660</td>\n",
       "      <td>0.689305</td>\n",
       "      <td>0.571775</td>\n",
       "      <td>0.688531</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.573528</td>\n",
       "      <td>0.689289</td>\n",
       "      <td>0.569963</td>\n",
       "      <td>0.689688</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.574256</td>\n",
       "      <td>0.688422</td>\n",
       "      <td>0.569651</td>\n",
       "      <td>0.689469</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.573476</td>\n",
       "      <td>0.689406</td>\n",
       "      <td>0.569919</td>\n",
       "      <td>0.690094</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.572826</td>\n",
       "      <td>0.689305</td>\n",
       "      <td>0.572640</td>\n",
       "      <td>0.692500</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.572631</td>\n",
       "      <td>0.689344</td>\n",
       "      <td>0.572985</td>\n",
       "      <td>0.689531</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.573056</td>\n",
       "      <td>0.688695</td>\n",
       "      <td>0.568171</td>\n",
       "      <td>0.691625</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.572697</td>\n",
       "      <td>0.689563</td>\n",
       "      <td>0.568225</td>\n",
       "      <td>0.692563</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.572247</td>\n",
       "      <td>0.689867</td>\n",
       "      <td>0.569773</td>\n",
       "      <td>0.691688</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.571760</td>\n",
       "      <td>0.689797</td>\n",
       "      <td>0.568863</td>\n",
       "      <td>0.692438</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.572096</td>\n",
       "      <td>0.689281</td>\n",
       "      <td>0.569128</td>\n",
       "      <td>0.692438</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.571603</td>\n",
       "      <td>0.690195</td>\n",
       "      <td>0.572504</td>\n",
       "      <td>0.686813</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.571523</td>\n",
       "      <td>0.690805</td>\n",
       "      <td>0.573043</td>\n",
       "      <td>0.689719</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_loss  train_Accuracy  val_loss  val_Accuracy  epoch\n",
       "0     0.589603        0.675500  0.579704      0.681781      1\n",
       "1     0.579434        0.683906  0.588434      0.675813      2\n",
       "2     0.578238        0.683984  0.572195      0.686688      3\n",
       "3     0.576355        0.687398  0.574973      0.685250      4\n",
       "4     0.575338        0.687922  0.570307      0.691031      5\n",
       "5     0.574660        0.689305  0.571775      0.688531      6\n",
       "6     0.573528        0.689289  0.569963      0.689688      7\n",
       "7     0.574256        0.688422  0.569651      0.689469      8\n",
       "8     0.573476        0.689406  0.569919      0.690094      9\n",
       "9     0.572826        0.689305  0.572640      0.692500     10\n",
       "10    0.572631        0.689344  0.572985      0.689531     11\n",
       "11    0.573056        0.688695  0.568171      0.691625     12\n",
       "12    0.572697        0.689563  0.568225      0.692563     13\n",
       "13    0.572247        0.689867  0.569773      0.691688     14\n",
       "14    0.571760        0.689797  0.568863      0.692438     15\n",
       "15    0.572096        0.689281  0.569128      0.692438     16\n",
       "16    0.571603        0.690195  0.572504      0.686813     17\n",
       "17    0.571523        0.690805  0.573043      0.689719     18"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(\n",
    "    classify_model, optimizer,\n",
    "    loss_fn, metrics_dict=metric_dict,\n",
    "    train_dataloader=train_dataloader, val_dataloader=val_dataloader,\n",
    "    monitor=\"val_Accuracy\", mode=\"max\",\n",
    "    epochs=50\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
