{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import importlib\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from model import BaselineTransformer\n",
    "from data import get_database_path, read_h5_file\n",
    "from utils import load_toml_config\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if sys.platform == \"darwin\" else \"cpu\"\n",
    "random_seed = 114514\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMD_config = load_toml_config(\"EMD\")\n",
    "particle_type_scale = EMD_config['particle_type_scale']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load raw events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = load_toml_config(\"file\")\n",
    "database_path = get_database_path()\n",
    "\n",
    "events = {}\n",
    "for key, value in files.items():\n",
    "    events[key] = read_h5_file(database_path, value)\n",
    "    print(key, events[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = [key for key in events.keys() if key != \"SM\"]\n",
    "print(signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hyper_parameters = load_toml_config(\"Transformer\")\n",
    "print(model_hyper_parameters)\n",
    "feature_size = model_hyper_parameters[\"feature_size\"]\n",
    "embed_size = model_hyper_parameters[\"embed_size\"]\n",
    "num_heads = model_hyper_parameters[\"num_heads\"]\n",
    "num_layers = model_hyper_parameters[\"num_layers\"]\n",
    "hidden_dim = model_hyper_parameters[\"hidden_dim\"]\n",
    "\n",
    "\n",
    "embedding_model = BaselineTransformer(feature_size, embed_size, num_heads, hidden_dim, num_layers)\n",
    "embedding_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis import create_exp_bkg_events, train_test_split, get_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio=0.2\n",
    "val_ratio = 0.2\n",
    "sig_lambda = 0\n",
    "n = 100000\n",
    "\n",
    "# test_signal = \"neutral_boson\"\n",
    "# test_signal = \"leptoquark\"\n",
    "# test_signal = \"neutral_Higgs\"\n",
    "test_signal = \"charged_Higgs\"\n",
    "\n",
    "exp_events, bkg_events = create_exp_bkg_events(events['SM'], events[test_signal], sig_lambda, n)\n",
    "X1, X2, W1, W2 = train_test_split(exp_events, bkg_events, test_ratio)\n",
    "n1 = len(W1)\n",
    "m1 = len(X1)\n",
    "pi = n1 / (n1 + m1)\n",
    "n2 = len(W2)\n",
    "m2 = len(X2)\n",
    "train_dataloader, val_dataloader = get_dataloaders(X1, W1, val_ratio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
